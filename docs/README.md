<div class="content hideonphone">
  <div class="content__container">
    <h1 class="content__container__text">
      The Science of
    </h1>
    <ul class="content__container__list">
     <li class="content__container__list__item">Social&nbsp;Cognition.</li>
      <li class="content__container__list__item">Disagreement.</li>
      <li class="content__container__list__item">Persuasion.</li>
      <li class="content__container__list__item">Belief Change.</li>
    </ul>
  </div>
</div>
<div class="hideonpc">
  <h1>Social Learning in Minds and Machines</h1>
</div>
A secret to our success as a species is our ability to learn from one another, and a secret failure mode of modern artificial intelligence is its inability to do so. 

My research studies the mechanisms that underlie **social learning**: how people and AI decide who to believe, when to trust, and when to doubt. I do this by building computational models and testing them with behavioral experiments. I pursue this work with two dovetailing aims.

First, my research explains why people are so good at learning from one another in some cases (e.g., through scientific inquiry and institutions), yet so quick to ignore one another in matters of deep societal import (e.g., when encountering political disagreement; [Psych Rev, 2025)](./assets/papers/Oktar_Beliefs_Persist.pdf){:target="_blank"}.

Second, I use these psychological insights to engineer AI systems that reason more effectively about social information. While people easily infer others‚Äô knowledge and intentions, even cutting-edge AI systems struggle with basic forms of social intelligence‚Äîsuch as detecting self-interested or manipulative sources of information [(NeurIPS, 2025)](./assets/papers/LLM_Vigilance.pdf){:target="_blank"}.

## Who am I?
I was born and raised in Istanbul (üßø); studied economics and cognitive science at Pomona College, CA (‚òÄÔ∏è); completed my PhD in Psychology at Princeton, NJ (‚ùÑÔ∏è); and am currently researching social cognition in Large Language Models at Meta in Seattle, WA (‚òî).

## Contact.
Feel free to contact me at oktar[dot]research[at]gmail.com with regards to research / collaboration / mentorship /... - I love talking about science. If you would like to send me anonymous feedback, [click here.](https://docs.google.com/forms/d/1t2G5ZI214eO0Qs7lT00XGp47SAOlQRsedRkwc87SUnY){:target="_blank"}

## Resources.
I want science to be more inclusive and rigorous. Here are some resources that can help with that:
- [Click here for](/advice.md){:target="_blank"} advice on succeeding in academia (currently focusing on graduate school applications). 
- [Click here for](/stats.md){:target="_blank"} some accessible/fun stats tutorials. 
- [Click here for](/intuition.md){:target="_blank"} intuitive explanations of some interesting problems.


<!-- - I study social cognition in minds and machines.

Human social capacities‚Äîfrom detecting persuasion to learning from opinion‚Äîremain out of reach for even the best artificial intelligence (AI) systems.

Clarifying the computations underlying these social capacities can therefore shed light on human cognition while helping us engineer better AI systems.

The following projects exemplify these dovetailing aims:

How does opinion influence belief?
My research has shown that people can draw rational inferences from others‚Äô opinions (Psych. Sci., 2024), and that societal dissent rarely changes our beliefs on important issues, from abortion to vaccination (Psych Rev, 2025). Our Paths to Persistence Model explains such robustness through three factors that distill decades of cross-disciplinary research (Nat. Rev. Psy., 2025) and that we can use to explain when interventions‚Äîsuch as persuasive conversations with AI (Arxiv, 2025)‚Äîwill succeed or fail.

How can AI systems vigilantly avoid manipulation?
For AI agents to be effective in the real world, they must critically evaluate opinions diverging from their own (Decision, 2024): for example, LLMs should discount claims made in sales pitches, while trusting reliable experts. My research has provided formal models of how such vigilance should operate rationally, and shown that human inferences are aligned with this model (Proc. CogSci, 2024). In ongoing research, we have shown that making salient the key components of this model through prompt-engineering improves LLMs‚Äô capacity for vigilance (NeurIPS, 2025).
Past research: judgment and decision-making.

In past research, I studied when deeply important beliefs‚Äîsuch as whether immigration restrictions are moral‚Äîcan be changed through courses in moral philosophy (Cognition, 2023); and have studied how people decide how to decide (Cognition, 2022).
Who am I?

I was born and raised in Istanbul (merhaba!); studied economics and cognitive science at Pomona College (CA); and completed my PhD in Psychology at Princeton (NJ). I am presently advancing research alongside a fantastic [community of collaborators](./collaborators.md){:target="_blank"}.

Resources.

I want science to be more inclusive and rigorous. Here are some resources that can help with that:

    Click here for advice on succeeding in academia (currently focusing on graduate school applications).
    Click here for a set of accessible and opinionated stats tutorials.
    Click here for intuitive explanations of some interesting problems.

Contact.

Feel free to contact me at oktar[dot]research[at]gmail.com with regards to research / collaboration / mentorship /‚Ä¶ - I love talking about science. If you would like to send me anonymous feedback, click here.
-->
  
